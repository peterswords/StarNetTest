{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess training and test set for StarNet\n",
    "This notebook takes you through the steps of how to pre-process the training data necessary for training StarNet and separate out a high S/N test set.\n",
    "\n",
    "Requirements:\n",
    "- python packages: `numpy h5py vos`\n",
    "* required data files: apStar_visits_main.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the file that contains individual visit spectra along with APOGEE data associated with each star**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset keys in file: \n",
      "\n",
      "['0_FE', '0_FE_ERR', 'ALPHA_M', 'AL_FE', 'AL_FE_ERR', 'CA_FE', 'CA_FE_ERR', 'C_FE', 'C_FE_ERR', 'FE_H', 'FE_H_ERR', 'IDs', 'K_FE', 'K_FE_ERR', 'LOGG', 'LOGG_ERR', 'MG_FE', 'MG_FE_ERR', 'MN_FE', 'MN_FE_ERR', 'NA_FE', 'NA_FE_ERR', 'NI_FE', 'NI_FE_ERR', 'N_FE', 'N_FE_ERR', 'PARAM', 'SI_FE', 'SI_FE_ERR', 'S_FE', 'S_FE_ERR', 'TEFF', 'TEFF_ERR', 'TI_FE', 'TI_FE_ERR', 'VRAD', 'VRAD_ERR', 'VSCATTER', 'V_FE', 'V_FE_ERR', 'aspcap_flag', 'bluegreen_persist', 'error_spectrum', 'greenred_persist', 'num_visits', 'spectrum', 'stacked_snr', 'star_flag', 'star_flag_indiv', 'targ1_flag', 'targ2_flag', 'visit_snr']\n",
      "['TEFF', 'FE_H', 'ALPHA_M', 'C_FE', 'N_FE', 'stacked_snr', 'LOGG', 'star_flag', 'aspcap_flag', 'VSCATTER']\n",
      "Obtained data for 143467 stars.\n",
      "main flags [113956]\n",
      "snr flags [53135]\n",
      "FE_H flags [53135]\n",
      "ALPHA_M flags [53135]\n",
      "C_FE flags [53131]\n",
      "N_FE flags [53128]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import GetData\n",
    "\n",
    "datadir = GetData.getDataDir()\n",
    "F = h5py.File(datadir + 'apStar_visits_main.h5','r')\n",
    "data = GetData.get(F, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the first **$num\\_ref$** visits for the reference set**\n",
    "\n",
    "We shuffle around the data to avoid local effects.\n",
    "Later on, it will be be split into training and cross-validation sets.\n",
    "The remaining high S/N spectra will be used in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference set includes 44784 individual visits from 14498 stars.\n"
     ]
    }
   ],
   "source": [
    "num_ref = 44784 # number of reference spectra\n",
    "\n",
    "indices_ref = data['indices'][0:num_ref]\n",
    "np.random.shuffle(indices_ref)\n",
    "\n",
    "ap_id_ref = data['IDs'][indices_ref]\n",
    "for p in GetData.getParams():\n",
    "    data[p] = data[p][indices_ref]\n",
    "\n",
    "print('Reference set includes '+str(len(ap_id_ref))+' individual visits from '+str(len(set(ap_id_ref)))+' stars.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now collect individual visit spectra, normalize each spectrum, and save data**\n",
    "\n",
    "**Normalize spectra**\n",
    "1. separate into three chips\n",
    "2. divide by median value in each chip\n",
    "3. recombine each spectrum into a vector of 7214 flux values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define edges of detectors\n",
    "blue_chip_begin = 322\n",
    "blue_chip_end = 3242\n",
    "green_chip_begin = 3648\n",
    "green_chip_end = 6048   \n",
    "red_chip_begin = 6412\n",
    "red_chip_end = 8306 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.h5 has been saved as the reference set to be used in 4_Train_Model.ipynb\n"
     ]
    }
   ],
   "source": [
    "savename = 'training_data.h5'\n",
    "\n",
    "with h5py.File(datadir + savename, \"w\") as f:\n",
    "    \n",
    "    # Create datasets for your reference data file \n",
    "    spectra_ds = f.create_dataset('spectrum', (1,7214), maxshape=(None,7214), dtype=\"f\", chunks=(1,7214))\n",
    "    ap_id_ds = f.create_dataset('Ap_ID', ap_id_ref.shape, dtype=\"S18\")\n",
    "    ap_id_ds[:] = ap_id_ref.tolist()\n",
    "    for p in GetData.getParams():\n",
    "        p_ds = f.create_dataset(p, data[p].shape, dtype=\"f\")\n",
    "        p_ds[:] = data[p]\n",
    "        \n",
    "    first_entry=True\n",
    "    \n",
    "    for i in indices_ref:\n",
    "\n",
    "        spectrum = F['spectrum'][i:i+1]\n",
    "        spectrum[np.isnan(spectrum)]=0.\n",
    "\n",
    "        # NORMALIZE SPECTRUM\n",
    "        # Separate spectra into chips\n",
    "        blue_sp = spectrum[0:1,blue_chip_begin:blue_chip_end]\n",
    "        green_sp = spectrum[0:1,green_chip_begin:green_chip_end]\n",
    "        red_sp = spectrum[0:1,red_chip_begin:red_chip_end]\n",
    "\n",
    "        # Normalize spectra by chips\n",
    "\n",
    "        blue_sp = (blue_sp.T/np.median(blue_sp, axis=1)).T\n",
    "        green_sp = (green_sp.T/np.median(green_sp, axis=1)).T\n",
    "        red_sp = (red_sp.T/np.median(red_sp, axis=1)).T \n",
    "\n",
    "        # Recombine spectra\n",
    "\n",
    "        spectrum = np.column_stack((blue_sp,green_sp,red_sp))\n",
    "        if first_entry:\n",
    "            spectra_ds[0] = spectrum\n",
    "            first_entry=False\n",
    "        else:\n",
    "            spectra_ds.resize(spectra_ds.shape[0]+1, axis=0)\n",
    "\n",
    "            spectra_ds[-1] = spectrum\n",
    "\n",
    "print(savename+' has been saved as the reference set to be used in 4_Train_Model.ipynb')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
